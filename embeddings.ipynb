{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed layer: conv1/conv -> conv1_conv\n",
      "Renamed layer: conv1/bn -> conv1_bn\n",
      "Renamed layer: conv1/relu -> conv1_relu\n",
      "Model file updated and saved.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import json\n",
    "\n",
    "def fix_model_h5_file(input_file, output_file):\n",
    "    with h5py.File(input_file, 'r') as f:\n",
    "        # Load model config (no .decode needed)\n",
    "        model_config = json.loads(f.attrs['model_config'])\n",
    "        layers = model_config['config']['layers']\n",
    "\n",
    "        # Fix layer names\n",
    "        for layer in layers:\n",
    "            if 'name' in layer['config'] and '/' in layer['config']['name']:\n",
    "                original_name = layer['config']['name']\n",
    "                fixed_name = original_name.replace('/', '_')\n",
    "                layer['config']['name'] = fixed_name\n",
    "                print(f\"Renamed layer: {original_name} -> {fixed_name}\")\n",
    "\n",
    "        # Update the model config\n",
    "        fixed_model_config = json.dumps(model_config)\n",
    "\n",
    "    # Save the fixed model\n",
    "    with h5py.File(output_file, 'w') as f_fixed:\n",
    "        # Copy weights from the original file\n",
    "        with h5py.File(input_file, 'r') as f:\n",
    "            for key in f.keys():\n",
    "                f.copy(key, f_fixed)\n",
    "        # Update the model configuration\n",
    "        f_fixed.attrs['model_config'] = fixed_model_config\n",
    "        print(\"Model file updated and saved.\")\n",
    "\n",
    "# Fix the problematic model file\n",
    "fix_model_h5_file('model.h5', 'fixed_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "model = load_model('fixed_model.h5')\n",
    "\n",
    "# Save the configuration and weights separately\n",
    "model_config = model.to_json()\n",
    "with open('model_config.json', 'w') as json_file:\n",
    "    json_file.write(model_config)\n",
    "\n",
    "model.save_weights('model.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7339 validated image filenames belonging to 46 classes.\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"./dataset/split-data/train_new.csv\")\n",
    "testgen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = testgen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=\"./dataset/img\",\n",
    "    x_col=\"img_path\",\n",
    "    y_col=\"category\",\n",
    "    target_size=(256, 256),\n",
    "    batch_size=128,\n",
    "    class_mode=\"categorical\",\n",
    "    workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paolo Canigiula\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m765s\u001b[0m 13s/step\n"
     ]
    }
   ],
   "source": [
    "# remove the last layer\n",
    "model = Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy, top_k_categorical_accuracy'])\n",
    "\n",
    "# save all the features for the test data\n",
    "features = model.predict(test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "58\n",
      "Processing batch: 50\n",
      "one loop\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4s/step\n",
      "Processing batch: 100\n",
      "one loop\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step\n",
      "Processing batch: 150\n",
      "one loop\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step\n",
      "Processing batch: 200\n",
      "one loop\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4s/step\n",
      "Processing batch: 250\n",
      "one loop\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4s/step\n",
      "Processing batch: 300\n",
      "one loop\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step\n",
      "Processing batch: 350\n",
      "one loop\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3s/step\n",
      "Processing batch: 400\n",
      "one loop\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3s/step\n",
      "Processing batch: 450\n",
      "one loop\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4s/step\n",
      "Processing batch: 500\n",
      "one loop\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step\n",
      "Features shape: (1280, 1024)\n",
      "First feature vector: [4.2270584e-04 2.6337025e-03 2.8178173e-03 ... 6.4261484e-01 7.8301504e-02\n",
      " 1.5077335e-01]\n"
     ]
    }
   ],
   "source": [
    "# test using the first element of test_generator\n",
    "import random\n",
    "\n",
    "feature_extractor = Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "\n",
    "# Initialize arrays for storing features, inputs, and labels\n",
    "features = []\n",
    "inputs = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "total_batches = len(test_generator)\n",
    "print(total_batches)\n",
    "# random_batch_indices = random.sample(range(total_batches), 300)\n",
    "print(len(test_generator))\n",
    "\n",
    "batch_index = 0\n",
    "\n",
    "for batch_x, batch_y in test_generator:\n",
    "    batch_index += 10\n",
    "\n",
    "    if batch_index % 50 != 0:\n",
    "        continue\n",
    "    print(\"Processing batch:\", batch_index)\n",
    "    # Stop when we've processed all batches\n",
    "    print(\"one loop\")\n",
    "    batch_features = feature_extractor.predict(batch_x)\n",
    "    \n",
    "    # Append features, inputs, and labels\n",
    "    features.append(batch_features)\n",
    "    inputs.append(batch_x)\n",
    "    labels.append(batch_y)\n",
    "    \n",
    "    #stop when len(features) reaches 30\n",
    "    if len(features) >= 10:\n",
    "        break\n",
    "\n",
    "image_paths = test_df[\"img_path\"].values\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "features = np.concatenate(features, axis=0)\n",
    "inputs = np.concatenate(inputs, axis=0)\n",
    "labels = np.concatenate(labels, axis=0)\n",
    "\n",
    "# Save features, inputs, and labels to a file\n",
    "data_to_save = {\n",
    "    'features': features,\n",
    "    'inputs': inputs,\n",
    "    'labels': labels,\n",
    "    'paths': image_paths\n",
    "}\n",
    "np.save('clothing_features_with_paths.npy', data_to_save)\n",
    "np.set_printoptions(threshold=1000) \n",
    "print(\"Features shape:\", features.shape)\n",
    "print(\"First feature vector:\", features[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\paolo canigiula\\anaconda3\\lib\\site-packages (1.9.0.post1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\paolo canigiula\\anaconda3\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\paolo canigiula\\appdata\\roaming\\python\\python312\\site-packages (from faiss-cpu) (24.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features and metadata saved for Faiss.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "features = features.astype('float32')\n",
    "\n",
    "np.save('faiss_features.npy', features)\n",
    "np.save('faiss_inputs.npy', inputs)\n",
    "np.save('faiss_labels.npy', labels)\n",
    "\n",
    "print(\"Features and metadata saved for Faiss.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped features: (1280, 1024)\n",
      "Features shape: (1280, 1024)\n",
      "Features data: [[4.22705838e-04 2.63370248e-03 2.81781727e-03 ... 6.42614841e-01\n",
      "  7.83015043e-02 1.50773346e-01]\n",
      " [1.57137591e-04 2.22004717e-03 4.67347074e-03 ... 8.85937870e-01\n",
      "  5.17713785e-01 7.16676712e-02]\n",
      " [5.22894319e-04 2.73222616e-03 4.25607990e-03 ... 1.31948262e-01\n",
      "  1.22066006e-01 1.01165867e+00]\n",
      " ...\n",
      " [4.69441555e-04 3.42909293e-03 5.06825838e-03 ... 4.59442705e-01\n",
      "  1.34897064e-02 5.20047903e-01]\n",
      " [3.78068013e-04 4.55600768e-03 3.53116100e-03 ... 2.89690197e-02\n",
      "  2.71299541e-01 9.71578479e-01]\n",
      " [3.72477749e-04 2.49885465e-03 3.13561363e-03 ... 2.39220119e+00\n",
      "  4.71160263e-02 5.65969467e-01]]\n",
      "Original features list length: 1280\n",
      "Shape of first batch in features list: (1024,)\n"
     ]
    }
   ],
   "source": [
    "# Example: If the feature vector dimensionality is known (e.g., 1024)\n",
    "d = 1024\n",
    "n_samples = features.size // d\n",
    "\n",
    "# Reshape the 1D array into 2D\n",
    "features = features.reshape(n_samples, d)\n",
    "print(\"Reshaped features:\", features.shape)\n",
    "\n",
    "print(\"Features shape:\", features.shape)\n",
    "print(\"Features data:\", features)  # Print some data to confirm\n",
    "print(\"Original features list length:\", len(features))\n",
    "print(\"Shape of first batch in features list:\", features[0].shape)  # Shape of individual batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors in the index: 1280\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "# Load saved features\n",
    "saved_data = np.load('clothing_features_with_paths.npy', allow_pickle=True).item()\n",
    "features = saved_data['features']\n",
    "image_paths = saved_data['paths']\n",
    "\n",
    "# Get dimensionality of features\n",
    "d = features.shape[1]  # Feature vector dimension\n",
    "\n",
    "# Create Faiss index (using L2 distance for exact search)\n",
    "index = faiss.IndexFlatL2(d)\n",
    "index.add(features)  # Add feature vectors to the index\n",
    "\n",
    "print(f\"Number of vectors in the index: {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# Load and preprocess the new input image\n",
    "new_input_path = \"./dataset/img_for_rec/IMG_5606.jpeg\"    # Replace with your image path\n",
    "img = load_img(new_input_path, target_size=(256, 256))  # Resize to match `target_size`\n",
    "img_array = img_to_array(img)  # Convert image to array\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension (1, H, W, C)\n",
    "\n",
    "# Create an ImageDataGenerator for preprocessing\n",
    "inputgen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Preprocess the new input\n",
    "new_input_generator = inputgen.flow(img_array, batch_size=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of labels: (1280,)\n",
      "Shape of features: (1280, 1024)\n",
      "Unique labels: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45]\n",
      "Shape of labels after conversion: (1280,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'c' argument has 1310720 elements, which is inconsistent with 'x' and 'y' with size 1280.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:4486\u001b[0m, in \u001b[0;36mAxes._parse_scatter_color_args\u001b[1;34m(c, edgecolors, kwargs, xsize, get_next_color_func)\u001b[0m\n\u001b[0;32m   4485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:  \u001b[38;5;66;03m# Is 'c' acceptable as PathCollection facecolors?\u001b[39;00m\n\u001b[1;32m-> 4486\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[43mmcolors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_rgba_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4487\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\colors.py:505\u001b[0m, in \u001b[0;36mto_rgba_array\u001b[1;34m(c, alpha)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 505\u001b[0m     rgba \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mto_rgba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcc\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m cc \u001b[38;5;129;01min\u001b[39;00m c])\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\colors.py:302\u001b[0m, in \u001b[0;36mto_rgba\u001b[1;34m(c, alpha)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rgba \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# Suppress exception chaining of cache lookup failure.\u001b[39;00m\n\u001b[1;32m--> 302\u001b[0m     rgba \u001b[38;5;241m=\u001b[39m \u001b[43m_to_rgba_no_colorcycle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\colors.py:393\u001b[0m, in \u001b[0;36m_to_rgba_no_colorcycle\u001b[1;34m(c, alpha)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(c) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]:\n\u001b[1;32m--> 393\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGBA sequence should have length 3 or 4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, Real) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m c):\n\u001b[0;32m    395\u001b[0m     \u001b[38;5;66;03m# Checks that don't work: `map(float, ...)`, `np.array(..., float)` and\u001b[39;00m\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;66;03m# `np.array(...).astype(float)` would all convert \"0.5\" to 0.5.\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: RGBA sequence should have length 3 or 4",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Plot the embeddings with labels\u001b[39;00m\n\u001b[0;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m---> 18\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduced_embeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduced_embeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtab10\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m plt\u001b[38;5;241m.\u001b[39mcolorbar()\n\u001b[0;32m     20\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2D Visualization of Embedding Space\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\pyplot.py:3699\u001b[0m, in \u001b[0;36mscatter\u001b[1;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[0;32m   3680\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mscatter)\n\u001b[0;32m   3681\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscatter\u001b[39m(\n\u001b[0;32m   3682\u001b[0m     x: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3697\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3698\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PathCollection:\n\u001b[1;32m-> 3699\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3701\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3702\u001b[0m \u001b[43m        \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3704\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmarker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmarker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3707\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3708\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3709\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3710\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlinewidths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinewidths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3711\u001b[0m \u001b[43m        \u001b[49m\u001b[43medgecolors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3712\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplotnonfinite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplotnonfinite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3713\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3714\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3715\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3716\u001b[0m     sci(__ret)\n\u001b[0;32m   3717\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\__init__.py:1465\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1462\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1464\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1467\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1468\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1469\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:4673\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[0;32m   4670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m edgecolors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4671\u001b[0m     orig_edgecolor \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   4672\u001b[0m c, colors, edgecolors \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m-> 4673\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_scatter_color_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medgecolors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_next_color_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_patches_for_fill\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_next_color\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4677\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m plotnonfinite \u001b[38;5;129;01mand\u001b[39;00m colors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4678\u001b[0m     c \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mmasked_invalid(c)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:4492\u001b[0m, in \u001b[0;36mAxes._parse_scatter_color_args\u001b[1;34m(c, edgecolors, kwargs, xsize, get_next_color_func)\u001b[0m\n\u001b[0;32m   4490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4491\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid_shape:\n\u001b[1;32m-> 4492\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m invalid_shape_exception(c\u001b[38;5;241m.\u001b[39msize, xsize) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   4493\u001b[0m     \u001b[38;5;66;03m# Both the mapping *and* the RGBA conversion failed: pretty\u001b[39;00m\n\u001b[0;32m   4494\u001b[0m     \u001b[38;5;66;03m# severe failure => one may appreciate a verbose feedback.\u001b[39;00m\n\u001b[0;32m   4495\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   4496\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument must be a color, a sequence of colors, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4497\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor a sequence of numbers, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: 'c' argument has 1310720 elements, which is inconsistent with 'x' and 'y' with size 1280."
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg8AAAH/CAYAAADQXz4mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAdO0lEQVR4nO3db2yW9b348U+h0KrntIs4Kwh2uOnGRuZGCYx6yDKnXdC4cLITu7iIOk3W7A9CjzuDcaKDLGm2k5nNTdgfQbMEXYP/4oMeZx+cIYjnbLB2WQaJizALs0haY4u6FYHr98BDz69rcXxqexfw9UruB/16Xff9vb+pXm+v6+51lxVFUQQAwCmaNNETAADOLOIBAEgRDwBAingAAFLEAwCQIh4AgBTxAACkiAcAIEU8AAAp4gEASEnHwzPPPBPXX399zJgxI8rKyuKJJ574u/ts3bo16urqorKyMi699NL48Y9/PJq5AgCngXQ8vP7663HFFVfEj370o1Paft++fXHttdfG4sWLo6OjI775zW/G8uXL49FHH01PFgCYeGXv5IuxysrK4vHHH4+lS5eedJtvfOMb8eSTT8aePXsGx5qamuJ3v/tdPPfcc6N9aQBggpSP9ws899xz0dDQMGTsM5/5TGzcuDHefPPNmDJlyrB9BgYGYmBgYPDn48ePxyuvvBLTpk2LsrKy8Z4yAJw1iqKIw4cPx4wZM2LSpLH5qOO4x8PBgwejpqZmyFhNTU0cPXo0enp6Yvr06cP2aWlpibVr14731ADgXWP//v0xc+bMMXmucY+HiBh2tuDElZKTnUVYvXp1NDc3D/7c19cXl1xySezfvz+qqqrGb6IAcJbp7++PWbNmxT/+4z+O2XOOezxcdNFFcfDgwSFjhw4divLy8pg2bdqI+1RUVERFRcWw8aqqKvEAAKMwlpf9x/0+D4sWLYr29vYhY08//XTMnz9/xM87AACnt3Q8vPbaa9HZ2RmdnZ0R8dafYnZ2dkZXV1dEvHXJYdmyZYPbNzU1xYsvvhjNzc2xZ8+e2LRpU2zcuDHuvPPOsXkHAEBJpS9b7Ny5Mz71qU8N/nziswk333xzPPjgg9Hd3T0YEhERs2fPjra2tli5cmXcd999MWPGjLj33nvjc5/73BhMHwAotXd0n4dS6e/vj+rq6ujr6/OZBwBIGI9jqO+2AABSxAMAkCIeAIAU8QAApIgHACBFPAAAKeIBAEgRDwBAingAAFLEAwCQIh4AgBTxAACkiAcAIEU8AAAp4gEASBEPAECKeAAAUsQDAJAiHgCAFPEAAKSIBwAgRTwAACniAQBIEQ8AQIp4AABSxAMAkCIeAIAU8QAApIgHACBFPAAAKeIBAEgRDwBAingAAFLEAwCQIh4AgBTxAACkiAcAIEU8AAAp4gEASBEPAECKeAAAUsQDAJAiHgCAFPEAAKSIBwAgRTwAACniAQBIEQ8AQIp4AABSxAMAkCIeAIAU8QAApIgHACBFPAAAKeIBAEgRDwBAingAAFLEAwCQIh4AgBTxAACkiAcAIEU8AAAp4gEASBEPAECKeAAAUsQDAJAiHgCAFPEAAKSIBwAgRTwAACniAQBIEQ8AQIp4AABSxAMAkCIeAIAU8QAApIgHACBFPAAAKeIBAEgRDwBAingAAFJGFQ/r16+P2bNnR2VlZdTV1cW2bdvedvvNmzfHFVdcEeeee25Mnz49br311ujt7R3VhAGAiZWOh9bW1lixYkWsWbMmOjo6YvHixbFkyZLo6uoacfvt27fHsmXL4rbbbos//OEPsWXLlvjNb34Tt99++zuePABQeul4uOeee+K2226L22+/PebMmRPf//73Y9asWbFhw4YRt//v//7veN/73hfLly+P2bNnxz/90z/Fl770pdi5c+c7njwAUHqpeDhy5Ejs2rUrGhoahow3NDTEjh07Rtynvr4+Dhw4EG1tbVEURbz88svxyCOPxHXXXTf6WQMAEyYVDz09PXHs2LGoqakZMl5TUxMHDx4ccZ/6+vrYvHlzNDY2xtSpU+Oiiy6K97znPfHDH/7wpK8zMDAQ/f39Qx4AwOlhVB+YLCsrG/JzURTDxk7YvXt3LF++PO66667YtWtXPPXUU7Fv375oamo66fO3tLREdXX14GPWrFmjmSYAMA7KiqIoTnXjI0eOxLnnnhtbtmyJf/7nfx4cv+OOO6KzszO2bt06bJ+bbrop/vrXv8aWLVsGx7Zv3x6LFy+Ol156KaZPnz5sn4GBgRgYGBj8ub+/P2bNmhV9fX1RVVV1ym8OAN7t+vv7o7q6ekyPoakzD1OnTo26urpob28fMt7e3h719fUj7vPGG2/EpElDX2by5MkR8dYZi5FUVFREVVXVkAcAcHpIX7Zobm6O+++/PzZt2hR79uyJlStXRldX1+BliNWrV8eyZcsGt7/++uvjscceiw0bNsTevXvj2WefjeXLl8eCBQtixowZY/dOAICSKM/u0NjYGL29vbFu3bro7u6OuXPnRltbW9TW1kZERHd395B7Ptxyyy1x+PDh+NGPfhT/+q//Gu95z3viqquuiu985ztj9y4AgJJJfeZhoozH9RoAeDeY8M88AACIBwAgRTwAACniAQBIEQ8AQIp4AABSxAMAkCIeAIAU8QAApIgHACBFPAAAKeIBAEgRDwBAingAAFLEAwCQIh4AgBTxAACkiAcAIEU8AAAp4gEASBEPAECKeAAAUsQDAJAiHgCAFPEAAKSIBwAgRTwAACniAQBIEQ8AQIp4AABSxAMAkCIeAIAU8QAApIgHACBFPAAAKeIBAEgRDwBAingAAFLEAwCQIh4AgBTxAACkiAcAIEU8AAAp4gEASBEPAECKeAAAUsQDAJAiHgCAFPEAAKSIBwAgRTwAACniAQBIEQ8AQIp4AABSxAMAkCIeAIAU8QAApIgHACBFPAAAKeIBAEgRDwBAingAAFLEAwCQIh4AgBTxAACkiAcAIEU8AAAp4gEASBEPAECKeAAAUsQDAJAiHgCAFPEAAKSIBwAgRTwAACniAQBIEQ8AQIp4AABSxAMAkCIeAIAU8QAApIgHACBlVPGwfv36mD17dlRWVkZdXV1s27btbbcfGBiINWvWRG1tbVRUVMT73//+2LRp06gmDABMrPLsDq2trbFixYpYv359XHnllfGTn/wklixZErt3745LLrlkxH1uuOGGePnll2Pjxo3xgQ98IA4dOhRHjx59x5MHAEqvrCiKIrPDwoULY968ebFhw4bBsTlz5sTSpUujpaVl2PZPPfVUfP7zn4+9e/fG+eefP6pJ9vf3R3V1dfT19UVVVdWongMA3o3G4xiaumxx5MiR2LVrVzQ0NAwZb2hoiB07doy4z5NPPhnz58+P7373u3HxxRfH5ZdfHnfeeWf85S9/OenrDAwMRH9//5AHAHB6SF226OnpiWPHjkVNTc2Q8Zqamjh48OCI++zduze2b98elZWV8fjjj0dPT098+ctfjldeeeWkn3toaWmJtWvXZqYGAJTIqD4wWVZWNuTnoiiGjZ1w/PjxKCsri82bN8eCBQvi2muvjXvuuScefPDBk559WL16dfT19Q0+9u/fP5ppAgDjIHXm4YILLojJkycPO8tw6NChYWcjTpg+fXpcfPHFUV1dPTg2Z86cKIoiDhw4EJdddtmwfSoqKqKioiIzNQCgRFJnHqZOnRp1dXXR3t4+ZLy9vT3q6+tH3OfKK6+Ml156KV577bXBseeffz4mTZoUM2fOHMWUAYCJlL5s0dzcHPfff39s2rQp9uzZEytXroyurq5oamqKiLcuOSxbtmxw+xtvvDGmTZsWt956a+zevTueeeaZ+PrXvx5f/OIX45xzzhm7dwIAlET6Pg+NjY3R29sb69ati+7u7pg7d260tbVFbW1tRER0d3dHV1fX4Pb/8A//EO3t7fG1r30t5s+fH9OmTYsbbrghvv3tb4/duwAASiZ9n4eJ4D4PADA6E36fBwAA8QAApIgHACBFPAAAKeIBAEgRDwBAingAAFLEAwCQIh4AgBTxAACkiAcAIEU8AAAp4gEASBEPAECKeAAAUsQDAJAiHgCAFPEAAKSIBwAgRTwAACniAQBIEQ8AQIp4AABSxAMAkCIeAIAU8QAApIgHACBFPAAAKeIBAEgRDwBAingAAFLEAwCQIh4AgBTxAACkiAcAIEU8AAAp4gEASBEPAECKeAAAUsQDAJAiHgCAFPEAAKSIBwAgRTwAACniAQBIEQ8AQIp4AABSxAMAkCIeAIAU8QAApIgHACBFPAAAKeIBAEgRDwBAingAAFLEAwCQIh4AgBTxAACkiAcAIEU8AAAp4gEASBEPAECKeAAAUsQDAJAiHgCAFPEAAKSIBwAgRTwAACniAQBIEQ8AQIp4AABSxAMAkCIeAIAU8QAApIgHACBFPAAAKeIBAEgRDwBAingAAFLEAwCQIh4AgJRRxcP69etj9uzZUVlZGXV1dbFt27ZT2u/ZZ5+N8vLy+NjHPjaalwUATgPpeGhtbY0VK1bEmjVroqOjIxYvXhxLliyJrq6ut92vr68vli1bFp/+9KdHPVkAYOKVFUVRZHZYuHBhzJs3LzZs2DA4NmfOnFi6dGm0tLScdL/Pf/7zcdlll8XkyZPjiSeeiM7OzlN+zf7+/qiuro6+vr6oqqrKTBcA3tXG4xiaOvNw5MiR2LVrVzQ0NAwZb2hoiB07dpx0vwceeCBeeOGFuPvuu0/pdQYGBqK/v3/IAwA4PaTioaenJ44dOxY1NTVDxmtqauLgwYMj7vPHP/4xVq1aFZs3b47y8vJTep2Wlpaorq4efMyaNSszTQBgHI3qA5NlZWVDfi6KYthYRMSxY8fixhtvjLVr18bll19+ys+/evXq6OvrG3zs379/NNMEAMbBqZ0K+F8XXHBBTJ48edhZhkOHDg07GxERcfjw4di5c2d0dHTEV7/61YiIOH78eBRFEeXl5fH000/HVVddNWy/ioqKqKioyEwNACiR1JmHqVOnRl1dXbS3tw8Zb29vj/r6+mHbV1VVxe9///vo7OwcfDQ1NcUHP/jB6OzsjIULF76z2QMAJZc68xAR0dzcHDfddFPMnz8/Fi1aFD/96U+jq6srmpqaIuKtSw5//vOf4+c//3lMmjQp5s6dO2T/Cy+8MCorK4eNAwBnhnQ8NDY2Rm9vb6xbty66u7tj7ty50dbWFrW1tRER0d3d/Xfv+QAAnLnS93mYCO7zAACjM+H3eQAAEA8AQIp4AABSxAMAkCIeAIAU8QAApIgHACBFPAAAKeIBAEgRDwBAingAAFLEAwCQIh4AgBTxAACkiAcAIEU8AAAp4gEASBEPAECKeAAAUsQDAJAiHgCAFPEAAKSIBwAgRTwAACniAQBIEQ8AQIp4AABSxAMAkCIeAIAU8QAApIgHACBFPAAAKeIBAEgRDwBAingAAFLEAwCQIh4AgBTxAACkiAcAIEU8AAAp4gEASBEPAECKeAAAUsQDAJAiHgCAFPEAAKSIBwAgRTwAACniAQBIEQ8AQIp4AABSxAMAkCIeAIAU8QAApIgHACBFPAAAKeIBAEgRDwBAingAAFLEAwCQIh4AgBTxAACkiAcAIEU8AAAp4gEASBEPAECKeAAAUsQDAJAiHgCAFPEAAKSIBwAgRTwAACniAQBIEQ8AQIp4AABSxAMAkCIeAIAU8QAApIgHACBFPAAAKeIBAEgRDwBAyqjiYf369TF79uyorKyMurq62LZt20m3feyxx+Kaa66J9773vVFVVRWLFi2KX/7yl6OeMAAwsdLx0NraGitWrIg1a9ZER0dHLF68OJYsWRJdXV0jbv/MM8/ENddcE21tbbFr16741Kc+Fddff310dHS848kDAKVXVhRFkdlh4cKFMW/evNiwYcPg2Jw5c2Lp0qXR0tJySs/xkY98JBobG+Ouu+46pe37+/ujuro6+vr6oqqqKjNdAHhXG49jaOrMw5EjR2LXrl3R0NAwZLyhoSF27NhxSs9x/PjxOHz4cJx//vkn3WZgYCD6+/uHPACA00MqHnp6euLYsWNRU1MzZLympiYOHjx4Ss/xve99L15//fW44YYbTrpNS0tLVFdXDz5mzZqVmSYAMI5G9YHJsrKyIT8XRTFsbCQPP/xwfOtb34rW1ta48MILT7rd6tWro6+vb/Cxf//+0UwTABgH5ZmNL7jggpg8efKwswyHDh0adjbib7W2tsZtt90WW7Zsiauvvvptt62oqIiKiorM1ACAEkmdeZg6dWrU1dVFe3v7kPH29vaor68/6X4PP/xw3HLLLfHQQw/FddddN7qZAgCnhdSZh4iI5ubmuOmmm2L+/PmxaNGi+OlPfxpdXV3R1NQUEW9dcvjzn/8cP//5zyPirXBYtmxZ/OAHP4hPfOITg2ctzjnnnKiurh7DtwIAlEI6HhobG6O3tzfWrVsX3d3dMXfu3Ghra4va2tqIiOju7h5yz4ef/OQncfTo0fjKV74SX/nKVwbHb7755njwwQff+TsAAEoqfZ+HieA+DwAwOhN+nwcAAPEAAKSIBwAgRTwAACniAQBIEQ8AQIp4AABSxAMAkCIeAIAU8QAApIgHACBFPAAAKeIBAEgRDwBAingAAFLEAwCQIh4AgBTxAACkiAcAIEU8AAAp4gEASBEPAECKeAAAUsQDAJAiHgCAFPEAAKSIBwAgRTwAACniAQBIEQ8AQIp4AABSxAMAkCIeAIAU8QAApIgHACBFPAAAKeIBAEgRDwBAingAAFLEAwCQIh4AgBTxAACkiAcAIEU8AAAp4gEASBEPAECKeAAAUsQDAJAiHgCAFPEAAKSIBwAgRTwAACniAQBIEQ8AQIp4AABSxAMAkCIeAIAU8QAApIgHACBFPAAAKeIBAEgRDwBAingAAFLEAwCQIh4AgBTxAACkiAcAIEU8AAAp4gEASBEPAECKeAAAUsQDAJAiHgCAFPEAAKSIBwAgRTwAACniAQBIEQ8AQIp4AABSxAMAkCIeAICUUcXD+vXrY/bs2VFZWRl1dXWxbdu2t91+69atUVdXF5WVlXHppZfGj3/841FNFgCYeOl4aG1tjRUrVsSaNWuio6MjFi9eHEuWLImurq4Rt9+3b19ce+21sXjx4ujo6IhvfvObsXz58nj00Uff8eQBgNIrK4qiyOywcOHCmDdvXmzYsGFwbM6cObF06dJoaWkZtv03vvGNePLJJ2PPnj2DY01NTfG73/0unnvuuVN6zf7+/qiuro6+vr6oqqrKTBcA3tXG4xhantn4yJEjsWvXrli1atWQ8YaGhtixY8eI+zz33HPR0NAwZOwzn/lMbNy4Md58882YMmXKsH0GBgZiYGBg8Oe+vr6IeGsBAIBTd+LYmTxX8LZS8dDT0xPHjh2LmpqaIeM1NTVx8ODBEfc5ePDgiNsfPXo0enp6Yvr06cP2aWlpibVr1w4bnzVrVma6AMD/6u3tjerq6jF5rlQ8nFBWVjbk56Ioho39ve1HGj9h9erV0dzcPPjzq6++GrW1tdHV1TVmb5y319/fH7NmzYr9+/e7VFQi1rz0rHnpWfPS6+vri0suuSTOP//8MXvOVDxccMEFMXny5GFnGQ4dOjTs7MIJF1100Yjbl5eXx7Rp00bcp6KiIioqKoaNV1dX+2UrsaqqKmteYta89Kx56Vnz0ps0aezuzpB6pqlTp0ZdXV20t7cPGW9vb4/6+voR91m0aNGw7Z9++umYP3/+iJ93AABOb+kMaW5ujvvvvz82bdoUe/bsiZUrV0ZXV1c0NTVFxFuXHJYtWza4fVNTU7z44ovR3Nwce/bsiU2bNsXGjRvjzjvvHLt3AQCUTPozD42NjdHb2xvr1q2L7u7umDt3brS1tUVtbW1ERHR3dw+558Ps2bOjra0tVq5cGffdd1/MmDEj7r333vjc5z53yq9ZUVERd99994iXMhgf1rz0rHnpWfPSs+alNx5rnr7PAwDw7ua7LQCAFPEAAKSIBwAgRTwAACmnTTz4mu/Sy6z5Y489Ftdcc028973vjaqqqli0aFH88pe/LOFszw7Z3/MTnn322SgvL4+Pfexj4zvBs1B2zQcGBmLNmjVRW1sbFRUV8f73vz82bdpUotmeHbJrvnnz5rjiiivi3HPPjenTp8ett94avb29JZrtme2ZZ56J66+/PmbMmBFlZWXxxBNP/N19xuT4WZwGfvGLXxRTpkwpfvaznxW7d+8u7rjjjuK8884rXnzxxRG337t3b3HuuecWd9xxR7F79+7iZz/7WTFlypTikUceKfHMz1zZNb/jjjuK73znO8Wvf/3r4vnnny9Wr15dTJkypfjtb39b4pmfubJrfsKrr75aXHrppUVDQ0NxxRVXlGayZ4nRrPlnP/vZYuHChUV7e3uxb9++4n/+53+KZ599toSzPrNl13zbtm3FpEmTih/84AfF3r17i23bthUf+chHiqVLl5Z45memtra2Ys2aNcWjjz5aRETx+OOPv+32Y3X8PC3iYcGCBUVTU9OQsQ996EPFqlWrRtz+3/7t34oPfehDQ8a+9KUvFZ/4xCfGbY5nm+yaj+TDH/5wsXbt2rGe2llrtGve2NhY/Pu//3tx9913i4ek7Jr/53/+Z1FdXV309vaWYnpnpeya/8d//Edx6aWXDhm79957i5kzZ47bHM9WpxIPY3X8nPDLFie+5vtvv7Z7NF/zvXPnznjzzTfHba5ni9Gs+d86fvx4HD58eEy/aOVsNto1f+CBB+KFF16Iu+++e7yneNYZzZo/+eSTMX/+/Pjud78bF198cVx++eVx5513xl/+8pdSTPmMN5o1r6+vjwMHDkRbW1sURREvv/xyPPLII3HdddeVYsrvOmN1/BzVt2qOpVJ9zTf/ZzRr/re+973vxeuvvx433HDDeEzxrDOaNf/jH/8Yq1atim3btkV5+YT/q3rGGc2a7927N7Zv3x6VlZXx+OOPR09PT3z5y1+OV155xeceTsFo1ry+vj42b94cjY2N8de//jWOHj0an/3sZ+OHP/xhKab8rjNWx88JP/Nwwnh/zTfDZdf8hIcffji+9a1vRWtra1x44YXjNb2z0qmu+bFjx+LGG2+MtWvXxuWXX16q6Z2VMr/nx48fj7Kysti8eXMsWLAgrr322rjnnnviwQcfdPYhIbPmu3fvjuXLl8ddd90Vu3btiqeeeir27ds3+H1JjL2xOH5O+P/OlOprvvk/o1nzE1pbW+O2226LLVu2xNVXXz2e0zyrZNf88OHDsXPnzujo6IivfvWrEfHWga0oiigvL4+nn346rrrqqpLM/Uw1mt/z6dOnx8UXXxzV1dWDY3PmzImiKOLAgQNx2WWXjeucz3SjWfOWlpa48sor4+tf/3pERHz0ox+N8847LxYvXhzf/va3nUkeY2N1/JzwMw++5rv0RrPmEW+dcbjlllvioYcecj0yKbvmVVVV8fvf/z46OzsHH01NTfHBD34wOjs7Y+HChaWa+hlrNL/nV155Zbz00kvx2muvDY49//zzMWnSpJg5c+a4zvdsMJo1f+ONN2LSpKGHosmTJ0fE//0fMWNnzI6fqY9XjpMTf9qzcePGYvfu3cWKFSuK8847r/jTn/5UFEVRrFq1qrjpppsGtz/xpyYrV64sdu/eXWzcuNGfaiZl1/yhhx4qysvLi/vuu6/o7u4efLz66qsT9RbOONk1/1v+2iIvu+aHDx8uZs6cWfzLv/xL8Yc//KHYunVrcdlllxW33377RL2FM052zR944IGivLy8WL9+ffHCCy8U27dvL+bPn18sWLBgot7CGeXw4cNFR0dH0dHRUUREcc899xQdHR2Dfxo7XsfP0yIeiqIo7rvvvqK2traYOnVqMW/evGLr1q2D/+zmm28uPvnJTw7Z/le/+lXx8Y9/vJg6dWrxvve9r9iwYUOJZ3zmy6z5Jz/5ySIihj1uvvnm0k/8DJb9Pf//iYfRya75nj17iquvvro455xzipkzZxbNzc3FG2+8UeJZn9mya37vvfcWH/7wh4tzzjmnmD59evGFL3yhOHDgQIlnfWb6r//6r7f9b/N4HT99JTcAkDLhn3kAAM4s4gEASBEPAECKeAAAUsQDAJAiHgCAFPEAAKSIBwAgRTwAACniAQBIEQ8AQIp4AABS/h/61TaOqM6jmAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Shape of labels:\", labels.shape)  # Should be (2560,)\n",
    "print(\"Shape of features:\", features.shape)  # Should be (2560, 1024)\n",
    "print(\"Unique labels:\", np.unique(labels))\n",
    "\n",
    "print(\"Shape of labels after conversion:\", labels.shape)\n",
    "\n",
    "# Reduce embedding dimensions to 2D for visualization\n",
    "tsne = TSNE(n_components=2, random_state=50)\n",
    "reduced_embeddings = tsne.fit_transform(features)\n",
    "\n",
    "# Plot the embeddings with labels\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], c=labels, cmap='tab10', s=5)\n",
    "plt.colorbar()\n",
    "plt.title(\"2D Visualization of Embedding Space\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step\n",
      "Extracted feature vector: [[0.00039874 0.00414509 0.00655918 ... 0.37406015 0.00655346 0.00411823]]\n",
      "28\n",
      "Shape of features[random_index]: [[5.7101308e-04 2.0826862e-03 3.2568020e-03 ... 9.7154692e-02\n",
      "  1.8454842e-01 9.4498086e-01]]\n",
      "img/Zip_Collar_Bomber/img_00000015.jpg\n",
      "Distances: [[  0.      334.85858 339.44626 347.26233 347.57147 347.87296 354.1346\n",
      "  354.8427  355.92914 356.1629  363.07626 363.49536 369.8474  370.2353\n",
      "  371.6496  371.67645 371.97006 372.54858 373.166   373.80005 375.63153\n",
      "  375.64383 375.71503 375.86374 378.34277 379.91516 381.7002  381.81873\n",
      "  383.15674 383.2425  384.1795  384.35443 384.4872  384.7363  387.34964\n",
      "  388.0191  388.39157 389.31866 389.58905 389.90915 391.60648 391.90253\n",
      "  392.0468  392.84402 392.8498  393.1496  393.33847 393.4428  393.75293\n",
      "  394.35175 394.35175 394.74182 394.90012 395.0121  395.5307  396.1775\n",
      "  397.3368  397.84103 398.2111  398.30817 398.67523 399.07086 399.52948\n",
      "  399.90396 400.1886  400.75214 400.76648 401.07278 401.10974 401.12518\n",
      "  401.43823 401.71677 402.15012 402.18134 402.34268 402.34448 402.74042\n",
      "  403.50342 403.5756  403.98206 404.2141  404.25012 404.94086 405.20453\n",
      "  407.04474 407.19055 407.58084 407.62872 408.70752 408.78406 408.78406\n",
      "  408.95898 409.0112  409.45267 409.9317  410.0567  410.24088 410.26746\n",
      "  410.35962 410.4691 ]]\n",
      "Indices: [[ 640  137 1130   88 1197  597  452  430  750  568  893  954  464  199\n",
      "   797   79  948 1247  656  107 1020  156  582  739  930  685 1139   29\n",
      "   342  837 1114 1237  552  645  280  300  579 1222  116  188  363 1160\n",
      "   376  740  138  434  428  399 1011   68  498 1080  197  762  446  312\n",
      "   522 1266  571  661  294  425  225  274 1233 1255  784  959  142  356\n",
      "   419 1167  238 1269  828  621  706  653 1220  352  562  130  569  847\n",
      "   702  217  518  332  393   44  360  816 1091  949  514  937  916   50\n",
      "   118  152]]\n",
      "['img/Zip_Collar_Bomber/img_00000015.jpg', 'img/Cropped_Open-Front_Blazer/img_00000086.jpg', 'img/Loose-Knit_Dolman_Cardigan/img_00000008.jpg', 'img/Hooded_Cotton_Canvas_Anorak/img_00000120.jpg', 'img/Diamond_Pattern_Cardigan/img_00000021.jpg', 'img/Quilted_Faux_Leather_Bomber/img_00000113.jpg', 'img/Sheer_Woven_Blouse/img_00000041.jpg', 'img/Animal_Print_Satin_Blouse/img_00000096.jpg', 'img/Classic_Collared_Button-Down/img_00000080.jpg', 'img/Zip_Collar_Bomber/img_00000072.jpg', 'img/Tartan_Plaid_Button-Down/img_00000102.jpg', 'img/Tile_Print_Drawstring_Caftan/img_00000048.jpg', 'img/Embroidered_Split_Neck_Peasant_Blouse/img_00000021.jpg', 'img/Collarless_Draped-Front_Blazer/img_00000081.jpg', 'img/Polka_Dot_Chambray_Button-Down/img_00000108.jpg', 'img/Hooded_Cotton_Canvas_Anorak/img_00000110.jpg', 'img/Tile_Print_Drawstring_Caftan/img_00000040.jpg', 'img/Tri-Stripe_Slim-Leg_Chinos/img_00000025.jpg', 'img/Quilted_Faux_Leather_Bomber/img_00000084.jpg', 'img/Hooded_Cotton_Canvas_Anorak/img_00000147.jpg', 'img/Drape-Front_Marled_Cardigan/img_00000005.jpg', 'img/Textured_Open_Front_Blazer/img_00000072.jpg', 'img/Quilted_Faux_Leather_Bomber/img_00000102.jpg', 'img/Tartan_Plaid_Button-Down/img_00000087.jpg', 'img/Tile_Print_Drawstring_Caftan/img_00000012.jpg', 'img/Zip_Collar_Bomber/img_00000044.jpg', 'img/Textured_Knit_Striped_Cardigan/img_00000013.jpg', 'img/Hooded_Cotton_Canvas_Anorak/img_00000042.jpg', 'img/Beaded_Laser-Cut_Blouse/img_00000003.jpg', 'img/Polka_Dot_Chambray_Button-Down/img_00000006.jpg', 'img/Classic_Cardigan/img_00000034.jpg', 'img/Paneled_Drawstring_Chinos/img_00000035.jpg', 'img/Zip_Collar_Bomber/img_00000079.jpg', 'img/Quilted_Faux_Leather_Bomber/img_00000043.jpg', 'img/Quilted_Open-Front_Blazer/img_00000113.jpg', 'img/Cuffed-Sleeve_Boyfriend_Blazer/img_00000051.jpg', 'img/Zip_Collar_Bomber/img_00000049.jpg', 'img/Contrast-Cuff_Chinos/img_00000038.jpg', 'img/Hooded_Cotton_Canvas_Anorak/img_00000156.jpg', 'img/Dropped_Lapel_Chiffon-Sleeved_Blazer/img_00000037.jpg', 'img/Crochet-Paneled_Graph_Print_Blouse/img_00000008.jpg', 'img/Embroidered_Longline_Cardigan/img_00000010.jpg', 'img/Dotted_Chiffon_Blouse/img_00000052.jpg', 'img/Classic_Collared_Button-Down/img_00000042.jpg', 'img/Longline_Boyfriend_Blazer/img_00000013.jpg', 'img/Open-Back_Blouse/img_00000018.jpg', 'img/Layered_Split-Front_Blouse/img_00000079.jpg', 'img/Crisscross_Neckline_Peasant_Blouse/img_00000011.jpg', 'img/Drawstring_Cargo_Capris/img_00000072.jpg', 'img/Hooded_Cotton_Canvas_Anorak/img_00000093.jpg', 'img/Ruffled_Floral_Blouse/img_00000003.jpg', 'img/Ruched_Open-Front_Cardigan/img_00000046.jpg', 'img/Zip_Pocket_Blazer/img_00000050.jpg', 'img/Classic_Collared_Button-Down/img_00000029.jpg', 'img/Split-Back_Pleated_Blouse/img_00000110.jpg', 'img/Zippered_Shawl_Collar_Blazer/img_00000031.jpg', 'img/Zip_Collar_Bomber/img_00000088.jpg', 'img/Classic_Twill_Chinos/img_00000013.jpg', 'img/Quilted_Faux_Leather_Bomber/img_00000079.jpg', 'img/Quilted_Faux_Leather_Bomber/img_00000052.jpg', 'img/Flat_Collar_Blazer/img_00000016.jpg', 'img/Watercolor_Floral_Print_Blouse/img_00000057.jpg', 'img/Tulip_Front_Blazer/img_00000094.jpg', 'img/Longline_Slit_Blazer/img_00000049.jpg', 'img/Flat-Front_Chinos/img_00000002.jpg', 'img/Paneled_Drawstring_Chinos/img_00000031.jpg', 'img/Polka_Dot_Chambray_Button-Down/img_00000037.jpg', 'img/Drawstring_Cargo_Capris/img_00000001.jpg', 'img/Floral_and_Bird_Print_Blazer/img_00000113.jpg', 'img/Boxy_Split-Neck_Blouse/img_00000015.jpg', 'img/High-Neck_Sheer_Blouse/img_00000066.jpg', 'img/Boucl&eacute;_Knit_Cardigan/img_00000024.jpg', 'img/Notched_Open-Front_Textured_Blazer/img_00000052.jpg', 'img/Slim_Cotton_Chinos/img_00000058.jpg', 'img/Polka_Dot_Chambray_Button-Down/img_00000018.jpg', 'img/Zip_Collar_Bomber/img_00000003.jpg', 'img/Zip_Collar_Bomber/img_00000071.jpg', 'img/Zip_Collar_Bomber/img_00000082.jpg', 'img/Contrast-Cuff_Chinos/img_00000009.jpg', 'img/Sheer_Lace_&_Chiffon_Blouse/img_00000011.jpg', 'img/Quilted_Faux_Leather_Bomber/img_00000080.jpg', 'img/Tribal_Print_Linen_Blazer/img_00000051.jpg', 'img/Quilted_Faux_Leather_Bomber/img_00000076.jpg', 'img/Classic_Collared_Button-Down/img_00000030.jpg', 'img/Quilted_Faux_Leather_Bomber/img_00000034.jpg', 'img/Cropped_Open-Front_Blazer/img_00000016.jpg', 'img/Boxy_Crochet-Paneled_Blouse/img_00000048.jpg', 'img/Chiffon_Curved_Hem_Blouse/img_00000029.jpg', 'img/Floral_Print_Tie-Front_Blouse/img_00000101.jpg', 'img/Hooded_Cotton_Canvas_Anorak/img_00000066.jpg', 'img/Split_V-Neck_Chiffon_Blouse/img_00000022.jpg', 'img/Tartan_Plaid_Button-Down/img_00000121.jpg', 'img/Chevron_Cutout_Back_Cardigan/img_00000047.jpg', 'img/Tile_Print_Drawstring_Caftan/img_00000041.jpg', 'img/High-Neck_Blouse/img_00000073.jpg', 'img/Tile_Print_Drawstring_Caftan/img_00000023.jpg', 'img/Tartan_Plaid_Button-Down/img_00000084.jpg', 'img/Hooded_Cotton_Canvas_Anorak/img_00000073.jpg', 'img/Hooded_Cotton_Canvas_Anorak/img_00000158.jpg', 'img/Boxy_Buttoned_Blazer/img_00000063.jpg']\n",
      "Original Label Category: 28\n",
      "[28, 26, 25, 24, 1, 29, 28, 5, 1, 13, 40, 25, 40, 37, 33, 11, 39, 25, 25, 20, 38, 41, 27, 25, 25, 14, 25, 2, 25, 11, 34, 1, 37, 20, 22, 20, 28, 28, 25, 14, 11, 26, 13, 9, 38, 13, 9, 28, 7, 24, 24, 14, 36, 28, 22, 40, 11, 10, 20, 15, 34, 15, 37, 33, 28, 24, 24, 2, 28, 28, 20, 4, 8, 24, 5, 2, 4, 33, 11, 34, 13, 26, 34, 40, 39, 7, 8, 29, 18, 34, 34, 9, 36, 24, 27, 34, 24, 21, 33, 1]\n",
      "Number of recommended images in the same category: 9 out of 100 images\n",
      "% categorically accurate : 0.09\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "import random\n",
    "\n",
    "random_index = random.randint(0, 1280) # should be number of image paths\n",
    "random_image_path = image_paths[random_index]\n",
    "#labels = np.argmax(labels, axis=1)\n",
    "\n",
    "original_label = labels[random_index]\n",
    "feature_extractor = Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "new_input_features = feature_extractor.predict(new_input_generator)\n",
    "random_features = features[random_index].reshape(1, -1)\n",
    "\n",
    "print(\"Extracted feature vector:\", new_input_features)\n",
    "print(labels[random_index])\n",
    "\n",
    "\n",
    "\n",
    "k = 100  # Number of neighbors to retrieve\n",
    "print(\"Shape of features[random_index]:\", random_features)\n",
    "print(image_paths[random_index])\n",
    "distances, indices = index.search(random_features, k)\n",
    "\n",
    "print(\"Distances:\", distances)\n",
    "print(\"Indices:\", indices)\n",
    "\n",
    "similar_image_paths = [image_paths[idx] for idx in indices[0]]\n",
    "similar_image_labels = [labels[idx] for idx in indices[0]]\n",
    "original_path = (\"./dataset/img/\" + random_image_path)\n",
    "print(similar_image_paths)\n",
    "\n",
    "# Display the original and similar images\n",
    "def display_images(original_path, similar_image_paths):\n",
    "    display(Image(filename = original_path))\n",
    "    \n",
    "    for path in similar_image_paths:\n",
    "        display(Image(filename=\"./dataset/img/\" + path))\n",
    "\n",
    "def similar_image_score(original_label, similar_image_labels):\n",
    "    print(\"Original Label Category: \" + str(original_label))  # Convert integer to string\n",
    "    print(str(similar_image_labels))\n",
    "\n",
    "    hits = 0\n",
    "    for label in similar_image_labels:\n",
    "        if original_label == label:  # Compare directly, no need for indexing\n",
    "            hits += 1\n",
    "        \n",
    "    print(\"Number of recommended images in the same category: \" + str(hits) + \" out of \"+ str(k) + \" images\")\n",
    "    print(\"% categorically accurate : \" + str(hits/k))\n",
    "\n",
    "#display_images(original_path, similar_image_paths)\n",
    "similar_image_score(original_label, similar_image_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
